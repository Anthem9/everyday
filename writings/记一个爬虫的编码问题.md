# 记一个爬虫的编码问题

在学校的时候照着写书写了一个爬虫，倒也简单，反正是照着葫芦画瓢，总共三个库requests，bs4和os。

基本需求也能实现，输入一个网址，自动爬取该主题下的所有图片。

但有一个问题始终解决不了，我想把这个主题的名字直接用做保存这些图片的文件夹名，可是主题的名字是中文的，用做文件夹名时总是乱码。

我想，应该是编码问题，看看网页源码，是国标码，我就改，用国标码解码，无果。

反复对照书上的代码和我的代码，一点不差呀，怎么就是解不出来？

看文档吧，我觉得是解码的问题，所以看的bs4的文档，常见问题里面还真有编码问题，官方还提供了一个DimmitCode()函数来自动检测编码。

结果试了试还是无果。

我彻底没辙了。

今天我重新解决这个问题，在谷歌上搜了搜，各种各样的回答都有，有说要decode又要encode的，试了试，编译器说没decode方法，我又一搜，python3里默认字符串都是UTF-8，没有decode，敢情这解决方案还停留在python2.

我一气之下干脆重构代码，这次没看书，直接把那解决方案上python2的代码改成python3版本的了。

还是用上DammitCode()函数，成了！

我心一喜，心道这函数可能更新了，支持这个国标码了。

当即用它修改原来的爬虫，失败。

我又输出它检测的编码格式，结果是None

？？？

什么鬼？怎么是None？

寻思半天，终于顿悟，这说明没解码啊，就是UTF-8.

去掉这个函数果然也能成功。

重构的代码正常运行，旧的就总是失败。我有心找出问题的原因，就一行一行的对照代码。

终于找出不同，好几个参数不一样，我又控制变量，最终发现是传入BeautifulSoup的参数不对，原代码用了requests对象的text方法返回的是字符串对象，也就是说已经解过一次码了，而且还解错了，后面我的解码格式再怎么对，解出来的也仍旧是乱码了，就好比翻译的狗屁不通的英语让再高明的翻译家也翻译不成中文；而新代码用的是content方法，返回的是二进制数据，就是一点改动也没有的原生数据，所以用正确的编码格式解码就能成功。



### 总结

1. 问题的根本原因还是不知道原理，尽信书了。
2. 多看文档。
3. 问问题要写明版本、环境等信息。
4. 每个库都有help函数，能查到所有API的用法。
5. 要有造轮子的能力，和不造轮子的觉悟。
6. 切忌抄不理解原理的代码，后患无穷。